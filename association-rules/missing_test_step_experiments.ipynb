{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing test step analysis through association rules\n",
    "\n",
    "In this notebook, we perform experiments with frequent itemset and association rule mining to discover patterns of occurrence of test steps and recommend test steps that are potentially missing from new test case descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import json\n",
    "import statistics as st\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer, RegexpTokenizer, sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.util import ngrams\n",
    "import math\n",
    "from statistics import mean\n",
    "import string\n",
    "from collections import defaultdict\n",
    "\n",
    "import collections\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "from typing import Iterator\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "from expects import (contain_exactly, equal, expect, have_keys)\n",
    "import attr\n",
    "from functools import partial\n",
    "from tabulate import tabulate\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.offline as offline\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from spacy.util import minibatch, compounding\n",
    "import random\n",
    "import spacy\n",
    "\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules, fpgrowth\n",
    "import time\n",
    "\n",
    "from efficient_apriori import apriori\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import Markdown as md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load pre-processed data\n",
    "For the missing test step module, with association rules, we apply all default pre-processing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the existing test cases and further select only the test steps to build the association rules\n",
    "existing_test_cases_path = 'training_testing_data/existing_test_cases.pkl'\n",
    "existing_test_cases_df = pd.read_pickle(existing_test_cases_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick visualize df\n",
    "existing_test_cases_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained Named Entity Recognition (NER) model\n",
    "nlp = spacy.load('custom_ner/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace names of game entities by their entity type (e.g., replace the name of a game zone by 'game_zone')\n",
    "for index, row in existing_test_cases_df.iterrows():\n",
    "    current_step = ' '.join(row['Step'])\n",
    "    step_text = nlp(current_step)\n",
    "    \n",
    "    if step_text.ents:\n",
    "        for ent in step_text.ents:\n",
    "            current_step = current_step[:ent.start_char] + ent.label_ + current_step[ent.end_char:]\n",
    "    else:\n",
    "        # No named entities found\n",
    "        pass\n",
    "    \n",
    "    # Update test step\n",
    "    existing_test_cases_df.iloc[index,6] = current_step.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and evaluate association rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_case_keys = list(set(existing_test_cases_df['Key']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through test cases to build and evaluate association rules\n",
    "# Start with the first 2,500 test cases to build rules and evaluate on the 2501th, add the 2501th to the set of 2,500 and repeat steps\n",
    "# Minimum confidence = 1 and lift above 1\n",
    "\n",
    "test_case_accuracy_dict = {}\n",
    "te = TransactionEncoder()\n",
    "\n",
    "for test_key_index in tqdm(range(2500,3322)):\n",
    "    rule_list = []\n",
    "    correct_case = 0\n",
    "    wrong_case = 0\n",
    "    accuracy_step_list = []\n",
    "    \n",
    "    training_set_keys = all_test_case_keys[:test_key_index]\n",
    "    testing_set_key = all_test_case_keys[test_key_index+1]\n",
    "    \n",
    "    existing_test_cases_training_df = existing_test_cases_df[existing_test_cases_df['Key'].isin(training_set_keys)]\n",
    "    \n",
    "    # Build associaiton rules with training set\n",
    "    test_step_identifier_dict = {}\n",
    "    identifier = 0\n",
    "    for index,row in existing_test_cases_training_df.iterrows():\n",
    "        step = tuple(row['Step'])\n",
    "        if step not in test_step_identifier_dict:\n",
    "            test_step_identifier_dict[step] = identifier\n",
    "            identifier += 1\n",
    "\n",
    "    test_case_transactions_dict = {}\n",
    "    for index,row in existing_test_cases_training_df.iterrows():\n",
    "        step = tuple(row['Step'])\n",
    "        step_identifier = test_step_identifier_dict[step]\n",
    "\n",
    "        test_case_key = row['Key']\n",
    "        if test_case_key not in test_case_transactions_dict:\n",
    "            test_case_transactions_dict[test_case_key] = [step_identifier]\n",
    "        else:\n",
    "            test_case_transactions_dict[test_case_key] += [step_identifier]\n",
    "\n",
    "    transactions_list = []\n",
    "    for key in test_case_transactions_dict:\n",
    "        transactions_list.append(test_case_transactions_dict[key]) \n",
    "\n",
    "    te_ary = te.fit(transactions_list).transform(transactions_list)\n",
    "    df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "    \n",
    "    # Get frequent sets of test steps (min support = 0.005)\n",
    "    frequent_itemsets = fpgrowth(df, min_support=0.005, use_colnames=True)\n",
    "    step_list_complete = existing_test_cases_df[existing_test_cases_df['Key']==testing_set_key]['Step'].tolist()\n",
    "    \n",
    "    for i in range(len(step_list_complete)):\n",
    "        correct_step = 0\n",
    "        wrong_step = 0\n",
    "        removed_step = step_list_complete[i]\n",
    "        try:\n",
    "            removed_step_id = [test_step_identifier_dict[tuple(removed_step)]]\n",
    "        except:\n",
    "            removed_step_id = -1\n",
    "        \n",
    "        step_list = [step_list_complete[j] for j in range(len(step_list_complete)) if j!=i]\n",
    "        identifier_list = []\n",
    "        for step in step_list:\n",
    "            try:\n",
    "                identifier = test_step_identifier_dict[tuple(step)]\n",
    "                identifier_list.append(identifier)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        identifier_look_for = tuple(set(identifier_list))\n",
    "        # If set of remaining test steps in the new test case appeared in existing test cases\n",
    "        if len(identifier_look_for) > 0:\n",
    "            a = frequent_itemsets[frequent_itemsets['itemsets'].map(len) == len(identifier_look_for)+1 ]\n",
    "            for index,row in a.iterrows():\n",
    "                if all(elem in list(row['itemsets'])  for elem in identifier_look_for):\n",
    "                    X = set(identifier_look_for)\n",
    "                    Y = set(list(row['itemsets'])) - set(identifier_look_for)\n",
    "                    rule = str(X) + '->' + str(Y)\n",
    "                    \n",
    "                    # Compute confidence of the rule\n",
    "                    support_X = float(frequent_itemsets[frequent_itemsets['itemsets'] == frozenset(list(X))]['support'])\n",
    "                    suport_XY = float(a[a['itemsets'] == frozenset(list(X) + list(Y))]['support'])\n",
    "                    confidence_XY = suport_XY/support_X\n",
    "                    \n",
    "                    # Compute lift of the rule\n",
    "                    support_Y = float(frequent_itemsets[frequent_itemsets['itemsets'] == frozenset(list(Y))]['support'])\n",
    "                    lift_XY = confidence_XY/support_Y\n",
    "                    \n",
    "                    # Select rules with min confidence of 1 and lift above 1\n",
    "                    if (confidence_XY == 1) and (lift_XY > 1):\n",
    "                        # Rule is valid, i.e., meet criteria\n",
    "                        rule_list.append(rule)\n",
    "                        if list(Y) == removed_step_id:\n",
    "                            correct_step += 1\n",
    "                            correct_case += 1\n",
    "                        else:\n",
    "                            wrong_step += 1\n",
    "                            wrong_case += 1\n",
    "        \n",
    "        try:\n",
    "            accuracy_step = correct_step / (correct_step + wrong_step)\n",
    "            accuracy_step_list.append(accuracy_step)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    try:\n",
    "        # Compute accuracy and save metrics\n",
    "        accuracy_case = correct_case / (correct_case + wrong_case)\n",
    "        test_case_accuracy_dict[testing_set_key] = [len(rule_list), rule_list, accuracy_case, accuracy_step_list]  \n",
    "        with open('missing_step_evaluation.txt', 'w') as file:\n",
    "            file.write(json.dumps(test_case_accuracy_dict)) # use `json.loads` to do the reverse  \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through test cases to build and evaluate association rules\n",
    "# Start with the first 2,500 test cases to build rules and evaluate on the 2501th, add the 2501th to the set of 2,500 and repeat steps\n",
    "# Minimum confidence = 0.5 and lift above 1\n",
    "\n",
    "test_case_accuracy_dict = {}\n",
    "te = TransactionEncoder()\n",
    "\n",
    "for test_key_index in tqdm(range(2500,3322)):\n",
    "    rule_list = []\n",
    "    correct_case = 0\n",
    "    wrong_case = 0\n",
    "    accuracy_step_list = []\n",
    "    \n",
    "    training_set_keys = all_test_case_keys[:test_key_index]\n",
    "    testing_set_key = all_test_case_keys[test_key_index+1]\n",
    "    \n",
    "    existing_test_cases_training_df = existing_test_cases_df[existing_test_cases_df['Key'].isin(training_set_keys)]\n",
    "    \n",
    "    # Build associaiton rules with training set\n",
    "    test_step_identifier_dict = {}\n",
    "    identifier = 0\n",
    "    for index,row in existing_test_cases_training_df.iterrows():\n",
    "        step = tuple(row['Step'])\n",
    "        if step not in test_step_identifier_dict:\n",
    "            test_step_identifier_dict[step] = identifier\n",
    "            identifier += 1\n",
    "\n",
    "    test_case_transactions_dict = {}\n",
    "    for index,row in existing_test_cases_training_df.iterrows():\n",
    "        step = tuple(row['Step'])\n",
    "        step_identifier = test_step_identifier_dict[step]\n",
    "\n",
    "        test_case_key = row['Key']\n",
    "        if test_case_key not in test_case_transactions_dict:\n",
    "            test_case_transactions_dict[test_case_key] = [step_identifier]\n",
    "        else:\n",
    "            test_case_transactions_dict[test_case_key] += [step_identifier]\n",
    "\n",
    "    transactions_list = []\n",
    "    for key in test_case_transactions_dict:\n",
    "        transactions_list.append(test_case_transactions_dict[key]) \n",
    "\n",
    "    te_ary = te.fit(transactions_list).transform(transactions_list)\n",
    "    df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "    \n",
    "    # Get frequent sets of test steps (min support = 0.005)\n",
    "    frequent_itemsets = fpgrowth(df, min_support=0.005, use_colnames=True)\n",
    "    step_list_complete = existing_test_cases_df[existing_test_cases_df['Key']==testing_set_key]['Step'].tolist()\n",
    "    \n",
    "    for i in range(len(step_list_complete)):\n",
    "        correct_step = 0\n",
    "        wrong_step = 0\n",
    "        removed_step = step_list_complete[i]\n",
    "        try:\n",
    "            removed_step_id = [test_step_identifier_dict[tuple(removed_step)]]\n",
    "        except:\n",
    "            removed_step_id = -1\n",
    "        \n",
    "        step_list = [step_list_complete[j] for j in range(len(step_list_complete)) if j!=i]\n",
    "        identifier_list = []\n",
    "        for step in step_list:\n",
    "            try:\n",
    "                identifier = test_step_identifier_dict[tuple(step)]\n",
    "                identifier_list.append(identifier)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        identifier_look_for = tuple(set(identifier_list))\n",
    "        # If set of remaining test steps in the new test case appeared in existing test cases\n",
    "        if len(identifier_look_for) > 0:\n",
    "            a = frequent_itemsets[frequent_itemsets['itemsets'].map(len) == len(identifier_look_for)+1 ]\n",
    "            for index,row in a.iterrows():\n",
    "                if all(elem in list(row['itemsets'])  for elem in identifier_look_for):\n",
    "                    X = set(identifier_look_for)\n",
    "                    Y = set(list(row['itemsets'])) - set(identifier_look_for)\n",
    "                    rule = str(X) + '->' + str(Y)\n",
    "                    \n",
    "                    # Compute confidence of the rule\n",
    "                    support_X = float(frequent_itemsets[frequent_itemsets['itemsets'] == frozenset(list(X))]['support'])\n",
    "                    suport_XY = float(a[a['itemsets'] == frozenset(list(X) + list(Y))]['support'])\n",
    "                    confidence_XY = suport_XY/support_X\n",
    "                    \n",
    "                    # Compute lift of the rule\n",
    "                    support_Y = float(frequent_itemsets[frequent_itemsets['itemsets'] == frozenset(list(Y))]['support'])\n",
    "                    lift_XY = confidence_XY/support_Y\n",
    "                    \n",
    "                    # Select rules with min confidence of 1 and lift above 1\n",
    "                    if (confidence_XY >= 0.5) and (lift_XY > 1):\n",
    "                        # Rule is valid, i.e., meet criteria\n",
    "                        rule_list.append(rule)\n",
    "                        if list(Y) == removed_step_id:\n",
    "                            correct_step += 1\n",
    "                            correct_case += 1\n",
    "                        else:\n",
    "                            wrong_step += 1\n",
    "                            wrong_case += 1\n",
    "        \n",
    "        try:\n",
    "            accuracy_step = correct_step / (correct_step + wrong_step)\n",
    "            accuracy_step_list.append(accuracy_step)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    try:\n",
    "        # Compute accuracy and save metrics\n",
    "        accuracy_case = correct_case / (correct_case + wrong_case)\n",
    "        test_case_accuracy_dict[testing_set_key] = [len(rule_list), rule_list, accuracy_case, accuracy_step_list]  \n",
    "        with open('missing_step_evaluation_confidence_05.txt', 'w') as file:\n",
    "            file.write(json.dumps(test_case_accuracy_dict)) # use `json.loads` to do the reverse  \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check results\n",
    "with open('missing_step_evaluation.txt') as f:\n",
    "    min_confidence_1 = json.load(f)\n",
    "\n",
    "number_rules_list = []\n",
    "accuracy_list = []\n",
    "for test_case_key, value in min_confidence_1.items():\n",
    "    number_rules_list.append(value[0])\n",
    "    accuracy_list.append(value[2])\n",
    "print(\"Total rules: \")\n",
    "print(sum(number_rules_list))\n",
    "print(\"Median rules per test case: \")\n",
    "print(st.median(number_rules_list))\n",
    "print(\"Average rules per test case: \")\n",
    "print(st.mean(number_rules_list))\n",
    "print(\"Median accuracy per test case: \")\n",
    "print(st.median(accuracy_list))\n",
    "print(\"Average accuracy per test case: \")\n",
    "print(st.mean(accuracy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check results\n",
    "with open('missing_step_evaluation_confidence_05.txt') as f:\n",
    "    min_confidence_05 = json.load(f)\n",
    "\n",
    "number_rules_list = []\n",
    "accuracy_list = []\n",
    "for test_case_key, value in min_confidence_05.items():\n",
    "    number_rules_list.append(value[0])\n",
    "    accuracy_list.append(value[2])\n",
    "\n",
    "print(\"Total rules: \")\n",
    "print(sum(number_rules_list))\n",
    "print(\"Median rules per test case: \")\n",
    "print(st.median(number_rules_list))\n",
    "print(\"Average rules per test case: \")\n",
    "print(st.mean(number_rules_list))\n",
    "print(\"Median accuracy per test case: \")\n",
    "print(st.median(accuracy_list))\n",
    "print(\"Average accuracy per test case: \")\n",
    "print(st.mean(accuracy_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
